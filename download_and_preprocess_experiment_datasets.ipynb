{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IDjvxBpbfPg",
    "tags": []
   },
   "source": [
    "# Cats VS Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGsTEhsza8SQ",
    "outputId": "9b8f2aa0-c961-4124-c0c1-dc9868706c62"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "def download_dataset(url: str, dest_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads a dataset from a given URL and saves it to the specified destination directory.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to download the dataset from.w\n",
    "        dest_dir (str): The directory path to save the downloaded dataset to.\n",
    "    \n",
    "    Returns:\n",
    "        str: The path to the downloaded file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        file_name = url.split(\"/\")[-1]\n",
    "        file_path = os.path.join(dest_dir, file_name)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"Downloading dataset...\")\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "        else:\n",
    "            print(\"Dataset already downloaded.\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while downloading the dataset: \", e)\n",
    "\n",
    "\n",
    "def extract_dataset(zip_file_path: str, dest_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Extracts a zip file to the specified destination directory.\n",
    "    \n",
    "    Args:\n",
    "        zip_file_path (str): The path to the zip file to extract.\n",
    "        dest_dir (str): The directory path to extract the zip file to.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while extracting the dataset: \", e)\n",
    "\n",
    "\n",
    "def organize_images(src_dir: str, dest_dir: str, class_sample_count: int = 1000) -> None:\n",
    "    \"\"\"\n",
    "    Organizes images from a source directory to a destination directory, renaming them according to their class and index.\n",
    "    \n",
    "    Args:\n",
    "        src_dir (str): The directory path of the source images.\n",
    "        dest_dir (str): The directory path to organize the images to.\n",
    "        class_sample_count (int, optional): The number of images to organize per class. Defaults to 20.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(src_dir):\n",
    "        class_dir = os.path.join(dest_dir, class_name)\n",
    "        class_src_dir = os.path.join(src_dir, class_name)\n",
    "        for i, file_name in enumerate(os.listdir(class_src_dir)):\n",
    "            if i == class_sample_count:\n",
    "                break\n",
    "            try:\n",
    "                file_ext = file_name.split(\".\")[-1]\n",
    "                file_dest_name = \"{}_{}.{}\".format(class_name, i, file_ext)\n",
    "                file_src_path = os.path.join(class_src_dir, file_name)\n",
    "                file_dest_path = os.path.join(dest_dir, file_dest_name)\n",
    "                os.rename(file_src_path, file_dest_path)\n",
    "            except Exception as e:\n",
    "                print(\"An error occurred in the main function: \", e)\n",
    "                class_sample_count += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    The main function to download, extract, and organize the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sample_count = 50\n",
    "        original_data_path = 'data/cats_and_dogs_filtered'\n",
    "        sampled_data_path = f'{original_data_path}_{sample_count}'\n",
    "        url_train = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "        file_path_train = download_dataset(url_train, 'data')\n",
    "        extract_dataset(file_path_train, 'data')\n",
    "        organize_images(os.path.join(original_data_path, 'train'), os.path.join(sampled_data_path, 'train'))\n",
    "        organize_images(os.path.join(original_data_path, 'validation'), os.path.join(sampled_data_path, 'test'))\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred in the main function: \", e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNOKC1qQbk5i"
   },
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_um3jqhRf2v"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    \"\"\"Load MNIST image data from a gzipped file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the gzipped file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 3D numpy array containing the image data.\n",
    "\n",
    "    Raises:\n",
    "        IOError: If the file cannot be opened.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            data = data.reshape(-1, 28, 28)\n",
    "            return data\n",
    "    except IOError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    \"\"\"Load MNIST label data from a gzipped file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the gzipped file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D numpy array containing the label data.\n",
    "\n",
    "    Raises:\n",
    "        IOError: If the file cannot be opened.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            return data\n",
    "    except IOError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_dataset():\n",
    "    # Download the dataset from Yann LeCun's website\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 'test-images.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 'test-labels.gz')\n",
    "\n",
    "    # Load the dataset into numpy arrays\n",
    "    train_images = load_mnist_images('train-images.gz')\n",
    "    train_labels = load_mnist_labels('train-labels.gz')\n",
    "    test_images = load_mnist_images('test-images.gz')\n",
    "    test_labels = load_mnist_labels('test-labels.gz')\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def main(createdirs=False):\n",
    "    \"\"\"\n",
    "    Downloads the MNIST dataset from Yann LeCun's website, loads it into numpy arrays, and saves the images as PNG files.\n",
    "\n",
    "    Args:\n",
    "        createdirs (bool): Whether to create directories to save images or not. Default is False.\n",
    "\n",
    "    Raises:\n",
    "        Exception: An error occurred while downloading or loading the dataset.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        train_images, train_labels, test_images, test_labels = download_dataset()\n",
    "        \n",
    "        sample_count = 50\n",
    "        original_data_path = 'data/mnist_images'\n",
    "        sampled_data_path = f'{original_data_path}_{sample_count}'\n",
    "        seperator = \"_\"\n",
    "        \n",
    "        if createdirs:\n",
    "            seperator = \"/\"\n",
    "            # Create directories to save images\n",
    "            if not os.path.exists(os.path.join(original_data_path, 'train')):\n",
    "                os.makedirs(os.path.join(original_data_path, 'train'))\n",
    "                for i in range(10):\n",
    "                    os.makedirs(f'{original_data_path}/train/{i}')\n",
    "\n",
    "            if not os.path.exists(os.path.join(original_data_path, 'test')):\n",
    "                os.makedirs(os.path.join(original_data_path, 'test'))\n",
    "                for i in range(10):\n",
    "                    os.makedirs(f'{original_data_path}/test/{i}')\n",
    "\n",
    "        os.makedirs(os.path.join(sampled_data_path, 'train'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(sampled_data_path, 'test'), exist_ok=True)\n",
    "\n",
    "        # Save images\n",
    "        train_counter = [0] * 10\n",
    "        test_counter = [0] * 10\n",
    "        \n",
    "        selected_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "        for i in range(train_images.shape[0]):\n",
    "            label = train_labels[i]\n",
    "            if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "            if train_counter[label] < sample_count:\n",
    "                plt.imsave(f'{sampled_data_path}/train/{label}{seperator}{train_counter[label]}.png', train_images[i], cmap='gray')\n",
    "                train_counter[label] += 1\n",
    "\n",
    "        for i in range(test_images.shape[0]):\n",
    "            label = test_labels[i]\n",
    "            if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "            if test_counter[label] < sample_count:\n",
    "                plt.imsave(f'{sampled_data_path}/test/{label}{seperator}{test_counter[label]}.png', test_images[i], cmap='gray')\n",
    "                test_counter[label] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN4UNMQ7O_8y"
   },
   "source": [
    "# STL-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkfOkfUNSdI4",
    "outputId": "b9304cf6-c7f3-4b0c-e3eb-6318c9545d19"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    Reads all images from the binary file and returns a numpy array of the images\n",
    "\n",
    "    Args:\n",
    "        path_to_data (str): The path to the binary data file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A numpy array of the images.\n",
    "    \"\"\"\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # Read the binary data\n",
    "        data = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # Reshape the data into individual images\n",
    "        images = np.reshape(data, (-1, 3, 96, 96))\n",
    "\n",
    "        # Transpose the images to the correct format: (num_images, height, width, channels)\n",
    "        images = np.transpose(images, (0, 2, 3, 1))\n",
    "        images_rotated = np.rot90(images, k=0, axes=(1, 2))\n",
    "        images_rotated = np.ascontiguousarray(np.transpose(images_rotated, (0, 2, 1, 3)))\n",
    "\n",
    "    return images_rotated\n",
    "\n",
    "\n",
    "def read_labels_from_file(path_to_labels):\n",
    "    \"\"\"\n",
    "    Reads all labels from the binary file and returns a numpy array of the labels\n",
    "\n",
    "    Args:\n",
    "        path_to_labels (str): The path to the binary labels file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A numpy array of the labels.\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        # Read the binary data\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the STL-10 dataset, and returns the train and test sets.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]: A tuple of the train_images,\n",
    "        train_labels, test_images, and test_labels numpy arrays.\n",
    "    \"\"\"\n",
    "    # Define the URL to download the dataset\n",
    "    url = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
    "\n",
    "    try:\n",
    "        # Download the file if it doesn't exist\n",
    "        if not os.path.exists('./data/stl10_binary.tar.gz'):\n",
    "            print(\"Downloading stl10_binary.tar.gz...\")\n",
    "            urllib.request.urlretrieve(url, './data/stl10_binary.tar.gz')\n",
    "\n",
    "        # Extract the file if it hasn't been extracted\n",
    "        if not os.path.exists('./data/stl10_binary'):\n",
    "            print(\"Extracting stl10_binary.tar.gz...\")\n",
    "            with tarfile.open('./data/stl10_binary.tar.gz', 'r:gz') as tar:\n",
    "                tar.extractall('./data')\n",
    "\n",
    "        # Load the dataset into numpy arrays\n",
    "        train_images = read_all_images('./data/stl10_binary/train_X.bin')\n",
    "        train_labels = read_labels_from_file('./data/stl10_binary/train_y.bin')\n",
    "        test_images = read_all_images('./data/stl10_binary/test_X.bin')\n",
    "        test_labels = read_labels_from_file('./data/stl10_binary/test_y.bin')\n",
    "\n",
    "        return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading or extracting the dataset: {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Downloads the STL-10 dataset and saves the training and test images with their corresponding labels in separate directories.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the download URL is unreachable.\n",
    "        IOError: If there is an error while reading or writing the image files.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Download and extract the dataset\n",
    "        train_images, train_labels, test_images, test_labels = download_and_extract()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading and extracting the dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Define the path to save the images\n",
    "    sample_count = 50\n",
    "    original_data_path = 'data/stl10_data'\n",
    "    sampled_data_path = f'{original_data_path}_{sample_count}'\n",
    "    train_dir = os.path.join(sampled_data_path,'train')\n",
    "    test_dir = os.path.join(sampled_data_path,'test')\n",
    "    \n",
    "    # Create the directories to save the images, if they don't already exist\n",
    "    try:\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the image directories: {e}\")\n",
    "        return\n",
    "    \n",
    "    selected_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    # Save the training images with labels\n",
    "    counter = np.zeros(11)\n",
    "    for i in range(train_images.shape[0]):\n",
    "        label = train_labels[i]\n",
    "        if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "        if counter[label] < sample_count:\n",
    "            filename = os.path.join(train_dir, f'{str(label)}_{counter[label]}.png')\n",
    "            image = train_images[i]\n",
    "            # Normalize the image\n",
    "            image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "            # Convert to uint8\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            try:\n",
    "                # Save the image\n",
    "                Image.fromarray(image).save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the training image: {e}\")\n",
    "                return\n",
    "            counter[label] += 1\n",
    "    \n",
    "    # Save the test images with labels\n",
    "    counter = np.zeros(11)\n",
    "    for i in range(test_images.shape[0]):\n",
    "        label = test_labels[i]\n",
    "        if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "        if counter[label] < sample_count:\n",
    "            filename = os.path.join(test_dir, f'{str(label)}_{counter[label]}.png')\n",
    "            image = test_images[i]\n",
    "            # Normalize the image\n",
    "            image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "            # Convert to uint8\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            try:\n",
    "                # Save the image\n",
    "                Image.fromarray(image).save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the test image: {e}\")\n",
    "                return\n",
    "            counter[label] += 1\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGgSFhyHXGnN"
   },
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XIeEfdfSdtr",
    "outputId": "c8244be3-5c4a-4af7-9201-b16c87226c9e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    Reads all images from the binary file and returns a numpy array of the images\n",
    "\n",
    "    Args:\n",
    "        path_to_data (str): The path to the binary data file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A numpy array of the images.\n",
    "    \"\"\"\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # Load the binary data\n",
    "        data_dict = pickle.load(f, encoding='bytes')\n",
    "        # Extract the images and reshape\n",
    "        images = np.reshape(data_dict[b'data'], (-1, 3, 32, 32))\n",
    "        # Transpose the images to the correct format: (num_images, height, width, channels)\n",
    "        images = np.transpose(images, (0, 2, 3, 1))\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_labels_from_file(path_to_labels):\n",
    "    \"\"\"\n",
    "    Reads all labels from the binary file and returns a numpy array of the labels\n",
    "\n",
    "    Args:\n",
    "        path_to_labels (str): The path to the binary labels file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A numpy array of the labels.\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        # Load the pickle data\n",
    "        labels_dict = pickle.load(f, encoding='bytes')\n",
    "        # Extract the labels\n",
    "        labels = np.array(labels_dict[b'labels'])\n",
    "    return labels\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the CIFAR-10 dataset, and returns the train and test sets.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]: A tuple of the train_images,\n",
    "        train_labels, test_images, and test_labels numpy arrays.\n",
    "    \"\"\"\n",
    "    # Define the URL to download the dataset\n",
    "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "\n",
    "    # Download the file if it doesn't exist\n",
    "    if not os.path.exists('./data/cifar-10-python.tar.gz'):\n",
    "        print(\"Downloading cifar-10-python.tar.gz...\")\n",
    "        urllib.request.urlretrieve(url, './cifar-10-python.tar.gz')\n",
    "\n",
    "    # Extract the file if it hasn't been extracted\n",
    "    if not os.path.exists('./data/cifar-10-batches-py'):\n",
    "        print(\"Extracting cifar-10-python.tar.gz...\")\n",
    "        with tarfile.open('./data/cifar-10-python.tar.gz', 'r:gz') as tar:\n",
    "            tar.extractall('./data')\n",
    "\n",
    "    # Load the dataset into numpy arrays\n",
    "    train_images = read_all_images('./data/cifar-10-batches-py/data_batch_1')\n",
    "    train_labels = read_labels_from_file('./data/cifar-10-batches-py/data_batch_1')\n",
    "    for i in range(2, 6):\n",
    "        temp_images = read_all_images(f'./data/cifar-10-batches-py/data_batch_{i}')\n",
    "        temp_labels = read_labels_from_file(f'./data/cifar-10-batches-py/data_batch_{i}')\n",
    "        train_images = np.concatenate([train_images, temp_images], axis=0)\n",
    "        train_labels = np.concatenate([train_labels, temp_labels], axis=0)\n",
    "    test_images = read_all_images('./data/cifar-10-batches-py/test_batch')\n",
    "    test_labels = read_labels_from_file('./data/cifar-10-batches-py/test_batch')\n",
    "    \n",
    "\n",
    "    return  (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Downloads the CIFAR-10 dataset and saves the training and test images with their corresponding labels in separate directories.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the download URL is unreachable.\n",
    "        IOError: If there is an error while reading or writing the image files.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Download and extract the dataset\n",
    "        (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading the dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Define the path to save the images\n",
    "    sample_count = 50\n",
    "    original_data_path = 'data/cifar10_data'\n",
    "    sampled_data_path = f'{original_data_path}_{sample_count}'\n",
    "    train_dir = os.path.join(sampled_data_path,'train')\n",
    "    test_dir = os.path.join(sampled_data_path,'test')\n",
    "    \n",
    "    # Create the directories to save the images, if they don't already exist\n",
    "    try:\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the image directories: {e}\")\n",
    "        return\n",
    "    \n",
    "    selected_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    # Save the training images with labels\n",
    "    counter = np.zeros(10)\n",
    "    for i in range(train_images.shape[0]):\n",
    "        label = train_labels[i][0]\n",
    "        if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "        if counter[label] < sample_count:\n",
    "            filename = os.path.join(train_dir, f'{str(label)}_{counter[label]}.png')\n",
    "            image = train_images[i]\n",
    "            # Convert to uint8\n",
    "            image = image.astype(np.uint8)\n",
    "            try:\n",
    "                # Save the image\n",
    "                Image.fromarray(image).save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the training image: {e}\")\n",
    "                return\n",
    "            counter[label] += 1\n",
    "    \n",
    "    # Save the test images with labels\n",
    "    counter = np.zeros(10)\n",
    "    for i in range(test_images.shape[0]):\n",
    "        label = test_labels[i][0]\n",
    "        if label not in selected_labels:\n",
    "                continue\n",
    "                \n",
    "        if counter[label] < sample_count:\n",
    "            filename = os.path.join(test_dir, f'{str(label)}_{counter[label]}.png')\n",
    "            image = test_images[i]\n",
    "            # Convert to uint8\n",
    "            image = image.astype(np.uint8)\n",
    "            try:\n",
    "                # Save the image\n",
    "                Image.fromarray(image).save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the test image: {e}\")\n",
    "                return\n",
    "            counter[label] += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNSIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "def download_dataset():\n",
    "    # Download the Fashion-MNIST dataset\n",
    "    train_dataset = FashionMNIST(root='./data', train=True, download=True)\n",
    "    test_dataset = FashionMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "    # Load the dataset into numpy arrays\n",
    "    train_images = train_dataset.data.numpy()\n",
    "    train_labels = train_dataset.targets.numpy()\n",
    "    test_images = test_dataset.data.numpy()\n",
    "    test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def main(createdirs=False):\n",
    "    \"\"\"\n",
    "    Downloads the Fashion-MNIST dataset, loads it into numpy arrays, and saves the images as PNG files.\n",
    "\n",
    "    Args:\n",
    "        createdirs (bool): Whether to create directories to save images or not. Default is False.\n",
    "\n",
    "    Raises:\n",
    "        Exception: An error occurred while downloading or loading the dataset.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        train_images, train_labels, test_images, test_labels = download_dataset()\n",
    "\n",
    "        sample_count = 50\n",
    "        original_data_path = 'data/fashion_mnist_images'\n",
    "        sampled_data_path = f'{original_data_path}_{sample_count}'\n",
    "        separator = \"_\"\n",
    "\n",
    "        if createdirs:\n",
    "            separator = \"/\"\n",
    "            # Create directories to save images\n",
    "            if not os.path.exists(os.path.join(original_data_path, 'train')):\n",
    "                os.makedirs(os.path.join(original_data_path, 'train'))\n",
    "                for i in range(10):\n",
    "                    os.makedirs(f'{original_data_path}/train/{i}')\n",
    "\n",
    "            if not os.path.exists(os.path.join(original_data_path, 'test')):\n",
    "                os.makedirs(os.path.join(original_data_path, 'test'))\n",
    "                for i in range(10):\n",
    "                    os.makedirs(f'{original_data_path}/test/{i}')\n",
    "\n",
    "        os.makedirs(os.path.join(sampled_data_path, 'train'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(sampled_data_path, 'test'), exist_ok=True)\n",
    "\n",
    "        # Save images\n",
    "        train_counter = [0] * 10\n",
    "        test_counter = [0] * 10\n",
    "\n",
    "        selected_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "        for i in range(train_images.shape[0]):\n",
    "            label = train_labels[i]\n",
    "            if label not in selected_labels:\n",
    "                continue\n",
    "\n",
    "            if train_counter[label] < sample_count:\n",
    "                plt.imsave(f'{sampled_data_path}/train/{label}{separator}{train_counter[label]}.png', train_images[i],\n",
    "                           cmap='gray')\n",
    "                train_counter[label] += 1\n",
    "\n",
    "        for i in range(test_images.shape[0]):\n",
    "            label = test_labels[i]\n",
    "            if label not in selected_labels:\n",
    "                continue\n",
    "\n",
    "            if test_counter[label] < sample_count:\n",
    "                plt.imsave(f'{sampled_data_path}/test/{label}{separator}{test_counter[label]}.png', test_images[i],\n",
    "                           cmap='gray')\n",
    "                test_counter[label] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
